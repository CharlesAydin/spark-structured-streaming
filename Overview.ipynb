{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.types._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[age: bigint, count: bigint]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = (spark.read\n",
    "  .option(\"header\", true)\n",
    "  .option(\"inferSchema\", true)\n",
    "  .json(\"data/people.json\"))\n",
    "  \n",
    "df.groupBy(\"age\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "- Introduction to Spark and Datasets (30 mintues)?\n",
    "    - (resilience, in memory, easy word count, lazy, etc ...)\n",
    "- Introduction to Spark Structured Streaming\n",
    "    - reduce, joining, etc ...\n",
    "- What's New?\n",
    "    - What's going on under the hood Tungsten / Catalyst\n",
    "    - Comparison to non-structured streaming\n",
    "- Building a Stremaing Application\n",
    "    - Meetup Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benefits of Tungsten\n",
    "\n",
    "While Spark has traditionally been focused on optimizing for inter-computer network IO Efficiency.  This was the major bottle neck in mapreduce and other traditional distributed computing systems.  At this point, Spark is now intra-computer memory and CPU bound.\n",
    "\n",
    "1. **Customized Memory Management:** Spark understands its own memory allocation needs better than the generic JVM garbage collector.  Tungsten takes advantage of this by using `sun.misc.Unsafe`, which exposes C-Style off-heap memory access.  The result is fewer unecessary garbage colleciton events and improved performance.\n",
    "1. **Binary Encoding:** Spark traditionally needed to serialized data to JVM objects, it now uses the Tungsten binary encoding.  This has two major advantages.  First, it decreases the memory footprint.  While \"ABCD\" would take 4 bytes of UTF-8 to encode, it would be stored using 48 bytes as a JVM object.  Second, instead of serializing into objects, it's able to perform many actions directly on the the raw binary encoding, reducing the computational overhead for serialization / deserialization.\n",
    "1. **Code Generation:** Spark historically used generic JVM function evaluation.  Given the virtual function lookups, automated boxing of primitive types, and other JVM overhead, this dramatically slows down the computation.  By using type information, Tungsten is able to generate byte code and speed up performance.\n",
    "1. **Cache-aware Computation:** Tungsten lays out its memory in a way that takes advantage of CPU cache locality to reduce cache spilling and speed up computations.\n",
    "\n",
    "For more information, check out [this blog post](https://databricks.com/blog/2015/04/28/project-tungsten-bringing-spark-closer-to-bare-metal.html) or [this presentation](http://www.slideshare.net/SparkSummit/deep-dive-into-project-tungsten-josh-rosen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val df = (spark.read\n",
    "  .option(\"header\", true)\n",
    "  .option(\"inferSchema\", true)\n",
    "  .json(\"data/people.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data from Implied Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val explicitSchema = StructType(\n",
    "  StructField(\"name\", StringType, false) ::\n",
    "  StructField(\"city\", StringType, true) ::\n",
    "  StructField(\"country\", StringType, true) ::\n",
    "  StructField(\"age\", IntegerType, true) :: Nil\n",
    ")\n",
    "\n",
    "val inExplicit = (spark.readStream\n",
    "  .schema(explicitSchema)\n",
    "  .format(\"csv\")\n",
    "  .option(\"header\", true)\n",
    "  .option(\"maxFilesPerTrigger\", 1)\n",
    "  .load(\"data/people.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType(StructField(Name,StringType,true), StructField( City,StringType,true), StructField(Country,StringType,true), StructField(Age,IntegerType,true))\n",
      "StructType(StructField(name,StringType,false), StructField(city,StringType,true), StructField(country,StringType,true), StructField(age,IntegerType,true))\n"
     ]
    }
   ],
   "source": [
    "val inImplied = (spark.read\n",
    "  .format(\"csv\")\n",
    "  .option(\"header\", true)\n",
    "  .option(\"inferSchema\", true)\n",
    "  .load(\"data/people.csv\"))\n",
    "  \n",
    "val impliedSchema = inImplied.schema\n",
    "\n",
    "println(impliedSchema)\n",
    "println(explicitSchema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data using Spark Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark._\n",
    "import org.apache.spark.streaming._\n",
    "\n",
    "val ssc = new StreamingContext(sc, Seconds(1))\n",
    "val lines = ssc.socketTextStream(\"localhost\", 9091)\n",
    "val words = lines.flatMap(_.split(\"\\\\W+\"))\n",
    "val wordCounts = words.map(word => (word, 1)).reduceByKey(_ + _)\n",
    "\n",
    "wordCounts.print()\n",
    "\n",
    "ssc.start()\n",
    "Thread.sleep(20000)\n",
    "ssc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apache_toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
