{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark, Datasets, and Structured Streaming\n",
    "\n",
    "- RDD\n",
    "- Resilient\n",
    "- Distributed\n",
    "- In RAM\n",
    "- etc ...\n",
    "\n",
    "<!--- Images from http://spark.apache.org/docs/latest/streaming-programming-guide.html --->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark in Action\n",
    "\n",
    "Below, we give a simple example of a Spark Program that counts the words in Shakespeare's Othello.  Notice how much more concise the code is compared to \n",
    "\n",
    "![](images/streaming-arch.png)\n",
    "\n",
    "![](images/streaming-flow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(i,803)\n",
      "(and,769)\n",
      "(the,756)\n",
      "(to,572)\n",
      "(of,470)\n",
      "(a,441)\n",
      "(my,427)\n",
      "(that,337)\n",
      "(you,335)\n",
      "(in,319)\n",
      "(iago,299)\n",
      "(othello,292)\n",
      "(not,278)\n",
      "(is,276)\n",
      "(it,244)\n",
      "(with,221)\n",
      "(for,219)\n",
      "(be,208)\n",
      "(your,207)\n",
      "(he,205)\n"
     ]
    }
   ],
   "source": [
    "// Load Data\n",
    "val lines = sc.textFile(\"data/othello.txt\")\n",
    "\n",
    "// Count words\n",
    "val counts = (lines.flatMap(line => line.split(\"\\\\s+\"))\n",
    "    .map(word => (word.toLowerCase, 1))\n",
    "    .reduceByKey(_ + _))\n",
    "    \n",
    "(counts.sortBy(_._2, ascending=false)\n",
    "    .take(20)\n",
    "    .foreach(println))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Exercise**:\n",
    "\n",
    "Spark interface allows you to do everything SQL might do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A More Complex Spark Example\n",
    "\n",
    "One common use case is joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Denise,10.0)\n",
      "(Charlie,40.0)\n",
      "(Amy,70.0)\n",
      "(Bob,20.0)\n"
     ]
    }
   ],
   "source": [
    "case class User(id: Int, name: String, email: String, country: String)\n",
    "case class Transaction(userid: Int, product: String, cost: Double)\n",
    "\n",
    "val users = (sc.textFile(\"data/users.csv\")\n",
    "    .map{ t =>\n",
    "        val p = t.split(\",\")\n",
    "        User(p(0).toInt, p(1), p(2), p(3))\n",
    "    })\n",
    "        \n",
    "val transactions = (sc.textFile(\"data/transactions.csv\")\n",
    "    .map{ t =>\n",
    "        val p = t.split(\",\")\n",
    "        Transaction(p(0).toInt, p(1), p(2).toDouble)\n",
    "    })\n",
    "\n",
    "val userTransactions = (users.map(u => (u.id, u.name))\n",
    "    .join(transactions.map(t => (t.userid, t.cost)))\n",
    ").values\n",
    "\n",
    "val transactionsByUsers = userTransactions.reduceByKey(_ + _).collect\n",
    "\n",
    "transactionsByUsers.foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Notice that there's a user (\"Edward\") who did not make a purchase.  He disappeared from `transactionsByUsers` because we were doing an (inner) `join`.  Instead, do a `leftOuterJoin` so we have a record that he spent nothing.  Notice that this returns an `Option`.  You may find `flatMap` useful for this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark and Datasets\n",
    "\n",
    "- RDDs are slow because of using Java serialization (can use Kryo)\n",
    "- Dataframes use Catalyst but don't provide type safety.\n",
    "\n",
    "http://www.agildata.com/apache-spark-rdd-vs-dataframe-vs-dataset/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An example with Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// Normally, run `import spark.implicits._`\n",
    "// There's a namespace collision in a Spark Notebook that requires this\n",
    "\n",
    "val sparkDummy = spark\n",
    "import sparkDummy.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|  value|count(1)|\n",
      "+-------+--------+\n",
      "|      i|     803|\n",
      "|    and|     769|\n",
      "|    the|     756|\n",
      "|     to|     572|\n",
      "|     of|     470|\n",
      "|      a|     441|\n",
      "|     my|     427|\n",
      "|   that|     337|\n",
      "|    you|     335|\n",
      "|     in|     319|\n",
      "|   iago|     299|\n",
      "|othello|     292|\n",
      "|    not|     278|\n",
      "|     is|     276|\n",
      "|     it|     244|\n",
      "|   with|     221|\n",
      "|    for|     219|\n",
      "|     be|     208|\n",
      "|   your|     207|\n",
      "|     he|     205|\n",
      "+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Load Data\n",
    "val text = (spark.read\n",
    "    .text(\"data/othello/part*\")\n",
    "    .as[String])\n",
    "\n",
    "// Count words\n",
    "val counts = (text.flatMap(line => line.split(\"\\\\s+\"))\n",
    "    .groupByKey(_.toLowerCase)\n",
    "    .count)\n",
    "\n",
    "// Display most common\n",
    "counts.orderBy($\"count(1)\" desc).show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured Streaming\n",
    "\n",
    "Structured Streaming is based on datasets.\n",
    "\n",
    "- word count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+-----+--------+\n",
      "|value|count(1)|\n",
      "+-----+--------+\n",
      "|  the|     206|\n",
      "|  and|     191|\n",
      "|   of|     166|\n",
      "|    i|     163|\n",
      "|   to|     147|\n",
      "|   my|     109|\n",
      "|    a|     105|\n",
      "|   in|      75|\n",
      "| with|      70|\n",
      "|   is|      68|\n",
      "| that|      59|\n",
      "| your|      57|\n",
      "|  you|      56|\n",
      "|  for|      53|\n",
      "|   it|      52|\n",
      "| have|      47|\n",
      "|  not|      46|\n",
      "|   be|      45|\n",
      "|   do|      42|\n",
      "|  but|      40|\n",
      "+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+-----+--------+\n",
      "|value|count(1)|\n",
      "+-----+--------+\n",
      "|  the|     407|\n",
      "|  and|     376|\n",
      "|    i|     293|\n",
      "|   to|     286|\n",
      "|   of|     268|\n",
      "|    a|     203|\n",
      "|   my|     158|\n",
      "|   in|     147|\n",
      "| that|     134|\n",
      "|   is|     129|\n",
      "|  you|     112|\n",
      "| with|     110|\n",
      "|  for|     109|\n",
      "| iago|      98|\n",
      "| your|      97|\n",
      "|  not|      94|\n",
      "|   it|      90|\n",
      "| this|      86|\n",
      "| have|      83|\n",
      "|   be|      82|\n",
      "+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 2\n",
      "-------------------------------------------\n",
      "+-------+--------+\n",
      "|  value|count(1)|\n",
      "+-------+--------+\n",
      "|    the|     518|\n",
      "|    and|     503|\n",
      "|      i|     461|\n",
      "|     to|     415|\n",
      "|     of|     349|\n",
      "|      a|     282|\n",
      "|     my|     261|\n",
      "|   that|     208|\n",
      "|     in|     201|\n",
      "|    you|     177|\n",
      "|     is|     172|\n",
      "|    not|     170|\n",
      "|   iago|     168|\n",
      "|    for|     154|\n",
      "|   with|     148|\n",
      "|   your|     141|\n",
      "|     be|     140|\n",
      "|     it|     139|\n",
      "|othello|     134|\n",
      "|    but|     119|\n",
      "+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 3\n",
      "-------------------------------------------\n",
      "+-------+--------+\n",
      "|  value|count(1)|\n",
      "+-------+--------+\n",
      "|    the|     634|\n",
      "|    and|     632|\n",
      "|      i|     619|\n",
      "|     to|     492|\n",
      "|     of|     409|\n",
      "|      a|     347|\n",
      "|     my|     346|\n",
      "|   that|     265|\n",
      "|     in|     260|\n",
      "|    you|     257|\n",
      "|   iago|     243|\n",
      "|    not|     229|\n",
      "|     is|     220|\n",
      "|othello|     213|\n",
      "|   with|     191|\n",
      "|     it|     187|\n",
      "|   your|     179|\n",
      "|    for|     178|\n",
      "|     be|     177|\n",
      "|     do|     160|\n",
      "+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 4\n",
      "-------------------------------------------\n",
      "+-------+--------+\n",
      "|  value|count(1)|\n",
      "+-------+--------+\n",
      "|      i|     783|\n",
      "|    and|     748|\n",
      "|    the|     725|\n",
      "|     to|     561|\n",
      "|     of|     455|\n",
      "|      a|     430|\n",
      "|     my|     423|\n",
      "|   that|     324|\n",
      "|    you|     322|\n",
      "|     in|     303|\n",
      "|   iago|     293|\n",
      "|othello|     281|\n",
      "|    not|     273|\n",
      "|     is|     270|\n",
      "|     it|     238|\n",
      "|   with|     219|\n",
      "|    for|     214|\n",
      "|     be|     202|\n",
      "|   your|     201|\n",
      "|     do|     198|\n",
      "+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 5\n",
      "-------------------------------------------\n",
      "+-------+--------+\n",
      "|  value|count(1)|\n",
      "+-------+--------+\n",
      "|      i|     803|\n",
      "|    and|     769|\n",
      "|    the|     756|\n",
      "|     to|     572|\n",
      "|     of|     470|\n",
      "|      a|     441|\n",
      "|     my|     427|\n",
      "|   that|     337|\n",
      "|    you|     335|\n",
      "|     in|     319|\n",
      "|   iago|     299|\n",
      "|othello|     292|\n",
      "|    not|     278|\n",
      "|     is|     276|\n",
      "|     it|     244|\n",
      "|   with|     221|\n",
      "|    for|     219|\n",
      "|     be|     208|\n",
      "|   your|     207|\n",
      "|     he|     205|\n",
      "+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Load Data\n",
    "val text = (spark.readStream\n",
    "    .option(\"maxFilesPerTrigger\", 1)\n",
    "    .text(\"data/othello/part*\")\n",
    "    .as[String])\n",
    "    \n",
    "// Count words\n",
    "val counts = (text.flatMap(line => line.split(\"\\\\s+\"))\n",
    "    .groupByKey(_.toLowerCase)\n",
    "    .count)\n",
    "    \n",
    "val query = (counts\n",
    "    .orderBy($\"count(1)\" desc)\n",
    "    .writeStream\n",
    "    .outputMode(\"complete\")\n",
    "    .format(\"console\")\n",
    "    .start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apache_toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
