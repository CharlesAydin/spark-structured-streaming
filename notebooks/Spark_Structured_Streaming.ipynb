{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Spark Structured Streaming\n",
    "\n",
    "- structured streaming\n",
    "- How does structured streaming differ from batch?  Unbounded\n",
    "\n",
    "http://hortonworks.com/hadoop-tutorial/introduction-spark-streaming/\n",
    "https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#programming-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val sparkDummy = spark\n",
    "import sparkDummy.implicits._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shall I compare thee to a summer’s day?\n",
      "Thou art more lovely and more temperate.\n",
      "Rough winds do shake the darling buds of May,\n",
      "And summer’s lease hath all too short a date.\n",
      "Sometime too hot the eye of heaven shines,\n",
      "And often is his gold complexion dimmed;\n",
      "And every fair from fair sometime declines,\n",
      "By chance, or nature’s changing course, untrimmed;\n",
      "But thy eternal summer shall not fade,\n",
      "Nor lose possession of that fair thou ow’st,\n",
      "Nor shall death brag thou wand’rest in his shade,\n",
      "When in eternal lines to Time thou grow’st.\n",
      "So long as men can breathe, or eyes can see,\n",
      "So long lives this, and this gives life to thee."
     ]
    }
   ],
   "source": [
    "import sys.process._\n",
    "\n",
    "\"more data/summer.txt\" !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createStream(port: Int, duration: Int) {\n",
    "    val lines = (spark.readStream\n",
    "        .format(\"socket\")\n",
    "        .option(\"host\", \"localhost\")\n",
    "        .option(\"port\", port)\n",
    "        .load())\n",
    "\n",
    "    val words = (lines\n",
    "        .as[String]\n",
    "        .flatMap(_.split(\"\\\\s+\")))\n",
    "\n",
    "    val wordCounts = words.groupByKey(_.toLowerCase).count().orderBy($\"count(1)\" desc)\n",
    "\n",
    "    val query = (wordCounts.writeStream\n",
    "        .outputMode(\"complete\")\n",
    "        .format(\"console\")\n",
    "        .start\n",
    "        .awaitTermination(duration))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val port = 9001\n",
    "\n",
    "// Broadcast file on port one line at time\n",
    "(new Thread {\n",
    "    override def run {\n",
    "        s\"scala Broadcast.scala ${port} data/summer.txt\" !\n",
    "    }\n",
    "}).start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+--------+--------+\n",
      "|   value|count(1)|\n",
      "+--------+--------+\n",
      "|    thee|       1|\n",
      "|summer’s|       1|\n",
      "|       i|       1|\n",
      "|    day?|       1|\n",
      "|   shall|       1|\n",
      "|       a|       1|\n",
      "|      to|       1|\n",
      "| compare|       1|\n",
      "+--------+--------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+--------+--------+\n",
      "|   value|count(1)|\n",
      "+--------+--------+\n",
      "|     and|       3|\n",
      "|    more|       2|\n",
      "|     too|       2|\n",
      "|summer’s|       2|\n",
      "|     the|       2|\n",
      "|      of|       2|\n",
      "|       a|       2|\n",
      "|     art|       1|\n",
      "|   often|       1|\n",
      "|    thou|       1|\n",
      "|  lovely|       1|\n",
      "|     hot|       1|\n",
      "|   winds|       1|\n",
      "|    thee|       1|\n",
      "|    buds|       1|\n",
      "| shines,|       1|\n",
      "|     eye|       1|\n",
      "|      is|       1|\n",
      "|    gold|       1|\n",
      "|   date.|       1|\n",
      "+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 2\n",
      "-------------------------------------------\n",
      "+--------+--------+\n",
      "|   value|count(1)|\n",
      "+--------+--------+\n",
      "|    thou|       4|\n",
      "|     and|       4|\n",
      "|      of|       3|\n",
      "|   shall|       3|\n",
      "|    fair|       3|\n",
      "|    more|       2|\n",
      "|     too|       2|\n",
      "|     nor|       2|\n",
      "|      in|       2|\n",
      "| eternal|       2|\n",
      "|summer’s|       2|\n",
      "|     the|       2|\n",
      "|       a|       2|\n",
      "|     his|       2|\n",
      "|sometime|       2|\n",
      "|      to|       2|\n",
      "|     art|       1|\n",
      "|   often|       1|\n",
      "|   fade,|       1|\n",
      "|     not|       1|\n",
      "+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 3\n",
      "-------------------------------------------\n",
      "+--------+--------+\n",
      "|   value|count(1)|\n",
      "+--------+--------+\n",
      "|     and|       5|\n",
      "|    thou|       4|\n",
      "|      of|       3|\n",
      "|   shall|       3|\n",
      "|    fair|       3|\n",
      "|      to|       3|\n",
      "|    more|       2|\n",
      "|     can|       2|\n",
      "|     too|       2|\n",
      "|     nor|       2|\n",
      "|      in|       2|\n",
      "| eternal|       2|\n",
      "|summer’s|       2|\n",
      "|    long|       2|\n",
      "|     the|       2|\n",
      "|      so|       2|\n",
      "|       a|       2|\n",
      "|     his|       2|\n",
      "|sometime|       2|\n",
      "|      or|       2|\n",
      "+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "createStream(port, 12000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming Netcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+-----+--------+\n",
      "|value|count(1)|\n",
      "+-----+--------+\n",
      "|   hi|       1|\n",
      "+-----+--------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+-----+--------+\n",
      "|value|count(1)|\n",
      "+-----+--------+\n",
      "|   hi|       2|\n",
      "|there|       1|\n",
      "+-----+--------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 2\n",
      "-------------------------------------------\n",
      "+-----+--------+\n",
      "|value|count(1)|\n",
      "+-----+--------+\n",
      "|there|       2|\n",
      "|   hi|       2|\n",
      "+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// run `nc -lk 9002` in bash and start typing!\n",
    "\n",
    "createStream(9002, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prasing Data using Case Classes and Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.catalyst.ScalaReflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ACTIVE]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+-------+-------------+-------+---+\n",
      "|   name|         city|country|age|\n",
      "+-------+-------------+-------+---+\n",
      "|    Amy|        Paris|     FR| 30|\n",
      "|    Bob|     New York|     US| 22|\n",
      "|Charlie|       London|     UK| 35|\n",
      "| Denise|San Francisco|     US| 22|\n",
      "+-------+-------------+-------+---+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+-------+------+-------+----+\n",
      "|   name|  city|country| age|\n",
      "+-------+------+-------+----+\n",
      "| Edward|London|     UK|  53|\n",
      "|Francis|      |     FR|  22|\n",
      "| George|London|     UK|null|\n",
      "+-------+------+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "case class Person(name: String, city: String, country: String, age: Option[Int])\n",
    "\n",
    "val caseSchema = (ScalaReflection\n",
    "    .schemaFor[Person]\n",
    "    .dataType\n",
    "    .asInstanceOf[StructType])\n",
    "\n",
    "val peopleStream = (spark.readStream\n",
    "  .schema(caseSchema)\n",
    "  .option(\"header\", true)  // Headers are matched to Person properties\n",
    "  .option(\"maxFilesPerTrigger\", 1)  // each file is read in a separate batch\n",
    "  .csv(\"data/people/\")\n",
    "  .as[Person])\n",
    "  \n",
    "(peopleStream.writeStream\n",
    "    .outputMode(\"append\")  // write results to screen\n",
    "    .format(\"console\")\n",
    "    .start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Filter in a Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ACTIVE]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+-------+------+-------+---+\n",
      "|   name|  city|country|age|\n",
      "+-------+------+-------+---+\n",
      "|Charlie|London|     UK| 35|\n",
      "+-------+------+-------+---+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+------+------+-------+----+\n",
      "|  name|  city|country| age|\n",
      "+------+------+-------+----+\n",
      "|Edward|London|     UK|  53|\n",
      "|George|London|     UK|null|\n",
      "+------+------+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(peopleStream.filter($\"country\" === \"UK\")\n",
    "    .writeStream\n",
    "    .outputMode(\"append\")  // write results to screen\n",
    "    .format(\"console\")\n",
    "    .start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Groupby in a Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ACTIVE]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+-----+--------+\n",
      "|value|count(1)|\n",
      "+-----+--------+\n",
      "|   US|       2|\n",
      "|   FR|       1|\n",
      "|   UK|       1|\n",
      "+-----+--------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+-----+--------+\n",
      "|value|count(1)|\n",
      "+-----+--------+\n",
      "|   US|       2|\n",
      "|   FR|       2|\n",
      "|   UK|       3|\n",
      "+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(peopleStream.groupByKey(_.country)\n",
    "    .count\n",
    "    .writeStream\n",
    "    .outputMode(\"complete\")\n",
    "    .format(\"console\")\n",
    "    .start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using SQL Aggregations Structured Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ACTIVE]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+-------+--------+\n",
      "|country|avg(age)|\n",
      "+-------+--------+\n",
      "|     US|    22.0|\n",
      "|     FR|    30.0|\n",
      "|     UK|    35.0|\n",
      "+-------+--------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+-------+--------+\n",
      "|country|avg(age)|\n",
      "+-------+--------+\n",
      "|     US|    22.0|\n",
      "|     FR|    26.0|\n",
      "|     UK|    44.0|\n",
      "+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(peopleStream.groupBy($\"country\")\n",
    "    .agg(avg($\"age\"))\n",
    "    .writeStream\n",
    "    .outputMode(\"complete\")\n",
    "    .format(\"console\")\n",
    "    .start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining with datasets\n",
    "\n",
    "- Broadcast variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ACTIVE]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+-------+---------+\n",
      "|country|sum(cost)|\n",
      "+-------+---------+\n",
      "|     EN|     20.0|\n",
      "|     FR|     50.0|\n",
      "+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "case class User(id: Int, name: String, email: String, country: String)\n",
    "case class Transaction(userid: Int, product: String, cost: Double)\n",
    "\n",
    "val userSchema = (ScalaReflection\n",
    "    .schemaFor[User]\n",
    "    .dataType\n",
    "    .asInstanceOf[StructType]\n",
    ")\n",
    "    \n",
    "val transactionSchema = (ScalaReflection\n",
    "    .schemaFor[Transaction]\n",
    "    .dataType\n",
    "    .asInstanceOf[StructType]\n",
    ")\n",
    "\n",
    "val users = (spark.read\n",
    "    .schema(userSchema)\n",
    "    .option(\"header\", true)\n",
    "    .csv(\"data/users.csv\")\n",
    "    .as[User]\n",
    ")\n",
    "  \n",
    "val transactionStream = (spark.readStream\n",
    "    .schema(transactionSchema)\n",
    "    .option(\"header\", true)\n",
    "    .csv(\"data/transactions.csv\")\n",
    "    .as[Transaction]\n",
    ")\n",
    "\n",
    "val spendingByCountry = (transactionStream\n",
    "    .join(users, users(\"id\") === transactionStream(\"userid\"))\n",
    "    .groupBy($\"country\")\n",
    "    .agg(sum($\"cost\")))\n",
    "    \n",
    "(spendingByCountry.writeStream\n",
    "    .outputMode(\"complete\")\n",
    "    .format(\"console\")\n",
    "    .start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apache_toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
