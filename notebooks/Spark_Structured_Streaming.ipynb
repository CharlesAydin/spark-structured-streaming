{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Spark Structured Streaming\n",
    "\n",
    "- structured streaming\n",
    "- How does structured streaming differ from batch?  Unbounded\n",
    "\n",
    "http://hortonworks.com/hadoop-tutorial/introduction-spark-streaming/\n",
    "https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#programming-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val sparkDummy = spark\n",
    "import sparkDummy.implicits._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Network Streaming Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createStream(port: Int, duration: Int) {\n",
    "    val lines = (spark.readStream\n",
    "        .format(\"socket\")\n",
    "        .option(\"host\", \"localhost\")\n",
    "        .option(\"port\", port)\n",
    "        .load())\n",
    "\n",
    "    val words = (lines\n",
    "        .as[String]\n",
    "        .flatMap(_.split(\"\\\\s+\")))\n",
    "\n",
    "    val wordCounts = words.groupByKey(_.toLowerCase).count().orderBy($\"count(1)\" desc)\n",
    "\n",
    "    val query = (wordCounts.writeStream\n",
    "        .outputMode(\"complete\")\n",
    "        .format(\"console\")\n",
    "        .start\n",
    "        .awaitTermination(duration))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shall I compare thee to a summer’s day?\n",
      "Thou art more lovely and more temperate.\n",
      "Rough winds do shake the darling buds of May,\n",
      "And summer’s lease hath all too short a date.\n",
      "Sometime too hot the eye of heaven shines,\n",
      "And often is his gold complexion dimmed;\n",
      "And every fair from fair sometime declines,\n",
      "By chance, or nature’s changing course, untrimmed;\n",
      "But thy eternal summer shall not fade,\n",
      "Nor lose possession of that fair thou ow’st,\n",
      "Nor shall death brag thou wand’rest in his shade,\n",
      "When in eternal lines to Time thou grow’st.\n",
      "So long as men can breathe, or eyes can see,\n",
      "So long lives this, and this gives life to thee."
     ]
    }
   ],
   "source": [
    "import sys.process._\n",
    "\n",
    "\"more notebooks/data/summer.txt\" !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val port = 9001\n",
    "\n",
    "(new Thread {\n",
    "    override def run {\n",
    "        s\"scala notebooks/Broadcast.scala ${port} notebooks/data/summer.txt\" !\n",
    "    }\n",
    "}).start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+--------+--------+\n",
      "|   value|count(1)|\n",
      "+--------+--------+\n",
      "|    thee|       1|\n",
      "|summer’s|       1|\n",
      "|       i|       1|\n",
      "|    day?|       1|\n",
      "|   shall|       1|\n",
      "|       a|       1|\n",
      "|      to|       1|\n",
      "| compare|       1|\n",
      "+--------+--------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+--------+--------+\n",
      "|   value|count(1)|\n",
      "+--------+--------+\n",
      "|    more|       2|\n",
      "|     too|       2|\n",
      "|summer’s|       2|\n",
      "|     the|       2|\n",
      "|     and|       2|\n",
      "|      of|       2|\n",
      "|       a|       2|\n",
      "|     art|       1|\n",
      "|    thou|       1|\n",
      "|  lovely|       1|\n",
      "|     hot|       1|\n",
      "|   winds|       1|\n",
      "|    thee|       1|\n",
      "|    buds|       1|\n",
      "| shines,|       1|\n",
      "|     eye|       1|\n",
      "|   date.|       1|\n",
      "|   lease|       1|\n",
      "| darling|       1|\n",
      "|    hath|       1|\n",
      "+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 2\n",
      "-------------------------------------------\n",
      "+--------+--------+\n",
      "|   value|count(1)|\n",
      "+--------+--------+\n",
      "|     and|       4|\n",
      "|    more|       2|\n",
      "|     too|       2|\n",
      "|summer’s|       2|\n",
      "|     the|       2|\n",
      "|      of|       2|\n",
      "|   shall|       2|\n",
      "|       a|       2|\n",
      "|    fair|       2|\n",
      "|sometime|       2|\n",
      "|     art|       1|\n",
      "|   often|       1|\n",
      "|    thou|       1|\n",
      "|   fade,|       1|\n",
      "|     not|       1|\n",
      "|      by|       1|\n",
      "|  lovely|       1|\n",
      "|     hot|       1|\n",
      "|     thy|       1|\n",
      "|  summer|       1|\n",
      "+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 3\n",
      "-------------------------------------------\n",
      "+--------+--------+\n",
      "|   value|count(1)|\n",
      "+--------+--------+\n",
      "|    thou|       4|\n",
      "|     and|       4|\n",
      "|      of|       3|\n",
      "|   shall|       3|\n",
      "|    fair|       3|\n",
      "|    more|       2|\n",
      "|     can|       2|\n",
      "|     too|       2|\n",
      "|     nor|       2|\n",
      "|      in|       2|\n",
      "| eternal|       2|\n",
      "|summer’s|       2|\n",
      "|     the|       2|\n",
      "|       a|       2|\n",
      "|     his|       2|\n",
      "|sometime|       2|\n",
      "|      or|       2|\n",
      "|      to|       2|\n",
      "|     art|       1|\n",
      "|   often|       1|\n",
      "+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 4\n",
      "-------------------------------------------\n",
      "+--------+--------+\n",
      "|   value|count(1)|\n",
      "+--------+--------+\n",
      "|     and|       5|\n",
      "|    thou|       4|\n",
      "|      of|       3|\n",
      "|   shall|       3|\n",
      "|    fair|       3|\n",
      "|      to|       3|\n",
      "|    more|       2|\n",
      "|     can|       2|\n",
      "|     too|       2|\n",
      "|     nor|       2|\n",
      "|      in|       2|\n",
      "| eternal|       2|\n",
      "|summer’s|       2|\n",
      "|    long|       2|\n",
      "|     the|       2|\n",
      "|      so|       2|\n",
      "|       a|       2|\n",
      "|     his|       2|\n",
      "|sometime|       2|\n",
      "|      or|       2|\n",
      "+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "createStream(port, 12000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Netcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+-----+--------+\n",
      "|value|count(1)|\n",
      "+-----+--------+\n",
      "|   hi|       1|\n",
      "+-----+--------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+-----+--------+\n",
      "|value|count(1)|\n",
      "+-----+--------+\n",
      "|   hi|       2|\n",
      "|there|       1|\n",
      "+-----+--------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 2\n",
      "-------------------------------------------\n",
      "+-----+--------+\n",
      "|value|count(1)|\n",
      "+-----+--------+\n",
      "|there|       2|\n",
      "|   hi|       2|\n",
      "+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// run `nc -lk 9000` in bash and start typing!\n",
    "\n",
    "createStream(9000, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prasing Data using Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.catalyst.ScalaReflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ACTIVE]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+-------+----+-------+----+\n",
      "|   name|city|country| age|\n",
      "+-------+----+-------+----+\n",
      "|Michael|null|   null|null|\n",
      "|   Andy|null|   null|  30|\n",
      "| Justin|null|   null|  19|\n",
      "| Justin|null|   null|  26|\n",
      "| Justin|null|   null|  15|\n",
      "+-------+----+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "case class Person(name: String, city: String, country: String, age: Int)\n",
    "\n",
    "val explicitSchema = StructType(\n",
    "  StructField(\"name\", StringType, false) ::\n",
    "  StructField(\"city\", StringType, true) ::\n",
    "  StructField(\"country\", StringType, true) ::\n",
    "  StructField(\"age\", IntegerType, true) :: Nil\n",
    ")\n",
    "\n",
    "val caseSchema = ScalaReflection.schemaFor[Person].dataType.asInstanceOf[StructType]\n",
    "\n",
    "val in = (spark.readStream\n",
    "  .schema(caseSchema)\n",
    "  .option(\"header\", true)\n",
    "  .option(\"maxFilesPerTrigger\", 1)\n",
    "  .json(\"data/people.json\")\n",
    "  .as[Person])\n",
    "  \n",
    "(in.writeStream\n",
    "    .outputMode(\"append\")\n",
    "    .format(\"console\")\n",
    "    .start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Unknown\n",
       "Message: Unable to retrieve error!\n",
       "StackTrace: "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "spark.readStream.load(\"data/people.csv\").as[Person]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[age: bigint, count: bigint]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = (spark.read\n",
    "  .option(\"header\", true)\n",
    "  .option(\"inferSchema\", true)\n",
    "  .json(\"data/people.json\"))\n",
    "  \n",
    "df.groupBy(\"age\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Reducer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining with datasets\n",
    "\n",
    "- Broadcast variables"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apache_toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
