{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.types._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[age: bigint, count: bigint]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = (spark.read\n",
    "  .option(\"header\", true)\n",
    "  .option(\"inferSchema\", true)\n",
    "  .json(\"data/people.json\"))\n",
    "  \n",
    "df.groupBy(\"age\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val df = (spark.read\n",
    "  .option(\"header\", true)\n",
    "  .option(\"inferSchema\", true)\n",
    "  .json(\"data/people.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data from Implied Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val explicitSchema = StructType(\n",
    "  StructField(\"name\", StringType, false) ::\n",
    "  StructField(\"city\", StringType, true) ::\n",
    "  StructField(\"country\", StringType, true) ::\n",
    "  StructField(\"age\", IntegerType, true) :: Nil\n",
    ")\n",
    "\n",
    "val inExplicit = (spark.readStream\n",
    "  .schema(explicitSchema)\n",
    "  .format(\"csv\")\n",
    "  .option(\"header\", true)\n",
    "  .option(\"maxFilesPerTrigger\", 1)\n",
    "  .load(\"data/people.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType(StructField(Name,StringType,true), StructField( City,StringType,true), StructField(Country,StringType,true), StructField(Age,IntegerType,true))\n",
      "StructType(StructField(name,StringType,false), StructField(city,StringType,true), StructField(country,StringType,true), StructField(age,IntegerType,true))\n"
     ]
    }
   ],
   "source": [
    "val inImplied = (spark.read\n",
    "  .format(\"csv\")\n",
    "  .option(\"header\", true)\n",
    "  .option(\"inferSchema\", true)\n",
    "  .load(\"data/people.csv\"))\n",
    "  \n",
    "val impliedSchema = inImplied.schema\n",
    "\n",
    "println(impliedSchema)\n",
    "println(explicitSchema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data using Spark Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark._\n",
    "import org.apache.spark.streaming._\n",
    "val ssc = new StreamingContext(sc, Seconds(1))\n",
    "val lines = ssc.socketTextStream(\"localhost\", 9999)\n",
    "val words = lines.flatMap(_.split(\"\\\\W+\"))\n",
    "val wordCounts = words.map(word => (word, 1)).reduceByKey(_ + _)\n",
    "\n",
    "wordCounts.print()\n",
    "\n",
    "ssc.start()\n",
    "ssc.awaitTerminationOrTimeout(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apache_toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
