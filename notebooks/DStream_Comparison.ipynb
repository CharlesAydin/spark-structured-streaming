{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val sparkDummy = spark\n",
    "import sparkDummy.implicits._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with DStream\n",
    "\n",
    "1. DStream made it hard to deal with late data because the DStream was just discretized batches\n",
    "1. Same API between batch Datasets and structured streaming\n",
    "1. Better end-to-end guarantees to handle fault-tolerant data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benefits of Tungsten\n",
    "\n",
    "While Spark has traditionally been focused on optimizing for inter-computer network IO Efficiency.  This was the major bottle neck in mapreduce and other traditional distributed computing systems.  At this point, Spark is now intra-computer memory and CPU bound.\n",
    "\n",
    "1. **Customized Memory Management:** Spark understands its own memory allocation needs better than the generic JVM garbage collector.  Tungsten takes advantage of this by using `sun.misc.Unsafe`, which exposes C-Style off-heap memory access.  The result is fewer unecessary garbage colleciton events and improved performance.\n",
    "1. **Binary Encoding:** Spark traditionally needed to serialized data to JVM objects, it now uses the Tungsten binary encoding.  This has two major advantages.  First, it decreases the memory footprint.  While \"ABCD\" would take 4 bytes of UTF-8 to encode, it would be stored using 48 bytes as a JVM object.  Second, instead of serializing into objects, it's able to perform many actions directly on the the raw binary encoding, reducing the computational overhead for serialization / deserialization.\n",
    "1. **Code Generation:** Spark historically used generic JVM function evaluation.  Given the virtual function lookups, automated boxing of primitive types, and other JVM overhead, this dramatically slows down the computation.  By using type information, Tungsten is able to generate byte code and speed up performance.\n",
    "1. **Cache-aware Computation:** Tungsten lays out its memory in a way that takes advantage of CPU cache locality to reduce cache spilling and speed up computations.\n",
    "\n",
    "For more information, check out [this blog post](https://databricks.com/blog/2015/04/28/project-tungsten-bringing-spark-closer-to-bare-metal.html) or [this presentation](http://www.slideshare.net/SparkSummit/deep-dive-into-project-tungsten-josh-rosen)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tungsten Performance Benefit\n",
    "\n",
    "The following two operations count a million integers in memory.\n",
    "- The first uses RDDs and must serialize all the objects into Java Objects.\n",
    "- The second use sTungsten and uses a more compact binary encoding.\n",
    "\n",
    "Tungsten saves a factor of nearly 4 on memory:\n",
    "\n",
    "![Tungsten Memory](images/Tungsten_Memory.png)\n",
    "\n",
    "To reproduce the example, run the following code and goto your Spark UI Viewer.  You can launch a new shell using `make spark-shell` (recommended), this will be at [http://localhost:5050/storage/](http://localhost:5050/storage/).  The default Spark UI port is 4040."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val million = 0 until math.pow(10, 6).toInt\n",
    "\n",
    "// Using RDDs\n",
    "sc.parallelize(million).cache.count\n",
    "\n",
    "// Using Tungsten\n",
    "million.toDF.cache.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benefits of Catalyst\n",
    "\n",
    "Optimizations include:\n",
    "1. **Constant Folding:** Evaluating constant expressions at compile time rather than at run time.\n",
    "1. **Predicate Pushdown:** Running operations that reduce the dataload (e.g. selecting columns or filtering rows) earlier in the query.  This reduces the amount of data that needs to be.\n",
    "1. **Boolean Expression Simplification:** Simplifies boolean expressions.\n",
    "1. **Projection Pruning:** Only read the columns (fields) used in a computation.\n",
    "1. **Pipelining Operations:** Combines multiple projection and filter operations into a single map operation.\n",
    "1. **Cost-based Optimization:** Spark actually builds multiple plans to compute a query, computes their cost, and chooses the cheapest one.\n",
    "1. **Code Generation:** The final operational plan is transformed into optimized Java bytecode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with DStream\n",
    "\n",
    "DStream semantics are different\n",
    "\n",
    "![dstream-ops](images/streaming-dstream.png)\n",
    "\n",
    "A\n",
    "![dstream-ops](images/streaming-dstream-ops.png)\n",
    "\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting Shakespeare in DStream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark._\n",
    "import org.apache.spark.streaming._\n",
    "\n",
    "val ssc = new StreamingContext(sc, Seconds(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scala.io.Source\n",
    "import org.apache.spark.streaming.receiver.Receiver\n",
    "import org.apache.spark.storage.StorageLevel\n",
    "\n",
    "// Should be a class ...\n",
    "def timedFileSource(fileName: String) = {\n",
    "    new Receiver[String](StorageLevel.MEMORY_AND_DISK_2) {\n",
    "        def onStart() {\n",
    "            new Thread(\"Timed File Source\") {\n",
    "                override def run() { receive() }\n",
    "            }.start()\n",
    "        }\n",
    "\n",
    "        def onStop() { }\n",
    "\n",
    "        private def receive() {\n",
    "            for (line <- Source.fromFile(fileName).getLines) {\n",
    "                println(line)\n",
    "                store(line)\n",
    "                Thread.sleep(1000L)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Syntax Error.\n",
       "Message: \n",
       "StackTrace: "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 1474572540000 ms\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 1474572541000 ms\n",
      "-------------------------------------------\n",
      "(Shall,1)\n",
      "(thee,1)\n",
      "(compare,1)\n",
      "(a,1)\n",
      "(I,1)\n",
      "(to,1)\n",
      "(day?,1)\n",
      "(summer’s,1)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 1474572542000 ms\n",
      "-------------------------------------------\n",
      "(Thou,1)\n",
      "(lovely,1)\n",
      "(temperate.,1)\n",
      "(more,2)\n",
      "(and,1)\n",
      "(art,1)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 1474572543000 ms\n",
      "-------------------------------------------\n",
      "(shake,1)\n",
      "(buds,1)\n",
      "(winds,1)\n",
      "(do,1)\n",
      "(May,,1)\n",
      "(of,1)\n",
      "(darling,1)\n",
      "(Rough,1)\n",
      "(the,1)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 1474572544000 ms\n",
      "-------------------------------------------\n",
      "(lease,1)\n",
      "(short,1)\n",
      "(date.,1)\n",
      "(too,1)\n",
      "(And,1)\n",
      "(a,1)\n",
      "(all,1)\n",
      "(hath,1)\n",
      "(summer’s,1)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 1474572545000 ms\n",
      "-------------------------------------------\n",
      "(shines,,1)\n",
      "(too,1)\n",
      "(heaven,1)\n",
      "(eye,1)\n",
      "(Sometime,1)\n",
      "(of,1)\n",
      "(hot,1)\n",
      "(the,1)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 1474572546000 ms\n",
      "-------------------------------------------\n",
      "(his,1)\n",
      "(gold,1)\n",
      "(is,1)\n",
      "(often,1)\n",
      "(complexion,1)\n",
      "(And,1)\n",
      "(dimmed;,1)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 1474572547000 ms\n",
      "-------------------------------------------\n",
      "(fair,2)\n",
      "(from,1)\n",
      "(And,1)\n",
      "(every,1)\n",
      "(declines,,1)\n",
      "(sometime,1)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 1474572548000 ms\n",
      "-------------------------------------------\n",
      "(chance,,1)\n",
      "(untrimmed;,1)\n",
      "(or,1)\n",
      "(course,,1)\n",
      "(nature’s,1)\n",
      "(changing,1)\n",
      "(By,1)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 1474572549000 ms\n",
      "-------------------------------------------\n",
      "(shall,1)\n",
      "(fade,,1)\n",
      "(summer,1)\n",
      "(not,1)\n",
      "(But,1)\n",
      "(thy,1)\n",
      "(eternal,1)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 1474572550000 ms\n",
      "-------------------------------------------\n",
      "(ow’st,,1)\n",
      "(possession,1)\n",
      "(fair,1)\n",
      "(thou,1)\n",
      "(Nor,1)\n",
      "(that,1)\n",
      "(of,1)\n",
      "(lose,1)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 1474572551000 ms\n",
      "-------------------------------------------\n",
      "(his,1)\n",
      "(death,1)\n",
      "(shall,1)\n",
      "(brag,1)\n",
      "(thou,1)\n",
      "(wand’rest,1)\n",
      "(Nor,1)\n",
      "(shade,,1)\n",
      "(in,1)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 1474572552000 ms\n",
      "-------------------------------------------\n",
      "(When,1)\n",
      "(thou,1)\n",
      "(lines,1)\n",
      "(eternal,1)\n",
      "(to,1)\n",
      "(Time,1)\n",
      "(in,1)\n",
      "(grow’st.,1)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 1474572553000 ms\n",
      "-------------------------------------------\n",
      "(So,1)\n",
      "(men,1)\n",
      "(long,1)\n",
      "(can,2)\n",
      "(as,1)\n",
      "(eyes,1)\n",
      "(breathe,,1)\n",
      "(or,1)\n",
      "(see,,1)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 1474572554000 ms\n",
      "-------------------------------------------\n",
      "(thee.,1)\n",
      "(So,1)\n",
      "(this,1)\n",
      "(long,1)\n",
      "(this,,1)\n",
      "(life,1)\n",
      "(gives,1)\n",
      "(to,1)\n",
      "(lives,1)\n",
      "(and,1)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 1474572555000 ms\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 1474572556000 ms\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 1474572557000 ms\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 1474572558000 ms\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 1474572559000 ms\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 1474572560000 ms\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 1474572561000 ms\n",
      "-------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(ssc.receiverStream(timedFileSource(\"data/summer.txt\"))\n",
    "    .flatMap(_.split(\" \"))\n",
    "    .map(word => (word, 1))\n",
    "    .reduceByKey(_ + _)\n",
    "    .print())\n",
    "\n",
    "ssc.start()             // Start the computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert picture of state update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Unknown\n",
       "Message: Unable to retrieve error!\n",
       "StackTrace: "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ssc = new StreamingContext(sc, Seconds(1))\n",
    "\n",
    "def updateFn(key: String, value: Option[Int], state: State[Int]) = {\n",
    "    // update state (stateful!)\n",
    "    state.update(value.getOrElse(0) + state.getOption.getOrElse(0))\n",
    "\n",
    "    // result to return\n",
    "    (key, state.get)\n",
    "}\n",
    "\n",
    "val spec = StateSpec.function(updateFn _)\n",
    "\n",
    "// checkpointing is mandatory\n",
    "ssc.checkpoint(\"_checkpoints\")\n",
    "\n",
    "(ssc.receiverStream(timedFileSource(\"data/summer.txt\"))\n",
    "    .flatMap(_.split(\" \"))\n",
    "    .map(word => (word, 1))\n",
    "    .mapWithState(spec)\n",
    "    .print)\n",
    "\n",
    "ssc.start()             // Start the computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with DStream API"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apache_toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
